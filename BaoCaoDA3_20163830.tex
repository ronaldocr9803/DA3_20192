\documentclass[a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage[left=3.5cm,right=2cm,top=3.5cm,bottom=3cm]{geometry}
%\documentclass{article}
%\usepackage{indentfirst}
\usepackage{graphicx}
\usepackage{enumitem}

\usepackage[vietnamese=nohyphenation]{hyphsubst}
\usepackage[vietnamese]{babel}
%\setlength{\parindent}{1cm} % Default is 15pt.

\usepackage{titlesec}

\titleformat*{\section}{\LARGE\bfseries}
\titleformat*{\subsection}{\Large\bfseries}
\titleformat*{\subsubsection}{\large\bfseries}
\titleformat*{\paragraph}{\large\bfseries}
\titleformat*{\subparagraph}{\large\bfseries}

\begin{document}
Để chứng minh định lý của Bregman, ta sử dụng 3 mệnh đề dưới đây:
\begin{enumerate}[label=\textbf{(\Alph*)}]
\item 
	$H(X) \leq \log_{2}(|supp X|)$. Dấu "$=$" xảy ra khi và chỉ khi X là phân phối đều trên $supp \text{ }X$ (tức $Prob(X=a) = \frac{1}{n}$ với $a \in supp \text{ }X,n=|supp \text{ }X|$ .
\\

\textit{\underline{Chứng minh:}} Không mất tính tổng quát, giả sử $p_{i} > 0$  $\forall i$. Áp dụng bất đẳng thức \textbf{AM-GM}: $a_{1}^{p_{1}}. ... .a_{n}^{p_{n}} \leq p_{1}a_{1}. ... .p_{n}a_{n}$: Đặt $a_{i} = \frac{1}{p_{i}}$ và lấy $\log$ 2 vế, ta được:
\begin{equation*}
H(X) = \displaystyle \sum_{i=1}^{n}p_{i}\log_{2}\frac{1}{p_{i}} \leq \log_{2}\Big(\displaystyle \sum_{i=1}^{n}p_{i}\frac{1}{p_{i}}\Big) = \log_{2}n.
\end{equation*}
Dấu "$=$" xảy ra khi và chỉ khi $p_{1} = ... = p_{n} = \frac{1}{n}$

\item 
	\(H(X,Y) = H(X) + H(Y|X)\), và tổng quát ta có \(H(X_{1},...,X_{n}) = H(X_{1}) + H(X_{2}|X{1}) + ... + H(X_{n}|X_{1},...,X_{n-1})\)
\\

\textit{\underline{Chứng minh:}}
\begin{equation*}
\begin{array}{l@{}l}
H(X,Y)
	&{}= \displaystyle -\sum_{i,j}p(a_{i},b_{j})\log_{2} p(a_{i},b_{j}) \\
	&{}= \displaystyle -\sum_{i,j}p(a_{i},b_{j})\log_{2} p(a_{i})p(b_{j}|a_{i}) \\ 
	&{}= \displaystyle -\sum_{i,j}p(a_{i},b_{j})[\log_{2}p(a_{i}) + \log_{2}p(b_{j}|a_{i}) ] \\
	&{}= \displaystyle -\sum_{i,j}p(a_{i},b_{j})\log_{2}p(a_{i})  \displaystyle -\sum_{i,j}p(a_{i},b_{j})\log_{2}p(b_{j}|a_{i}) \\
	&{}= \displaystyle -\sum_{i,j}p(a_{i},b_{j})\log_{2}p(a_{i}) \displaystyle -\sum_{i,j}p(a_{i}).p(b_{j}|a_{i})\log_{2}p(b_{j}|a_{i}) \\
	&{}= \displaystyle -\sum_{i=1}^{m}p(a_{i}) \log_{2}p(a_{i}) \displaystyle \sum_{j=1}^{n}p(b_{j}|a_{i}) + H(Y|X) \\
	&{}= \displaystyle -\sum_{i=1}^{m}p(a_{i}) \log_{2}p(a_{i}) + H(Y|X) = H(X) + H(Y|X) 
\end{array}
\end{equation*}
(Do $\displaystyle \sum_{j=1}^{n}p(b_{j}|a_{i}) = \displaystyle \sum_{j=1}^{n}\frac{P(b_{j}.a_{i})}{P(a_{i})} = \frac{1}{P(a_{i})}\displaystyle \sum_{j=1}^{n}P(b_{j}.a_{i})=\frac{1}{P(a_{i})}P(a_{i}) =1  $)

\item 
	Nếu \(supp\) \(X\) được chia thành d tập \(E_{1},..,E_{d}\) sao cho \(E_{j}:= \{a \in suppX : |supp(Y|a)| = j \} \) thì:
\begin{equation*}
    H(Y|X) \leq \sum_{j=1}^{d}Prob(X \in E_{j})\log_{2}j.
\end{equation*}
\\
\textit{\underline{Chứng minh:}} Ta có $supp(Y|a) = \{b: Prob(Y=b|X=a) > 0 \}$ .Vì $Prob(Y=b|X=a)$ là 1 biến ngẫu nhiên trên tập $supp$ $(Y|a)$ (Do $\displaystyle \sum_{i=1}^{m}Prob(Y=b_{i}|a) =1$) Tiến hành chia tập ${a_{1},...,a_{m}}$ thành các tập con $E_{j}$ theo giả thuyết và sử dụng kết quả từ \textbf{(A)}, ta có:
%$H(Y|X) = \displaystyle \sum_{i=1}^{m}p(a_{i})H(Y|a_{i}) $.  

\begin{equation*}
\begin{array}{l@{}l}
H(X,Y)
	&{} = \displaystyle \sum_{i=1}^{m}p(a_{i})H(Y|a_{i}) \\
	&{}= \displaystyle \sum _{j=1}^{d}\sum_{a \in E_{j}}p(a)H(Y|a) \\
	&{} \leq \displaystyle \sum _{j=1}^{d}\sum_{a \in E_{j}}p(a)\log_{2}j \\
	&{} = \displaystyle \sum_{j=1}^{d}Prob(X \in E_{j})\log_{2}j.
\end{array}
\end{equation*}

\end{enumerate}





\textbf{Định lý 1.}  Đặt $M = (m_{ij})$ là ma trận $n \times n$ chỉ chứa hai giá trị 0,1 và đặt $d_{1},...,d_{n}$  là tổng các hàng của ma trận $M$, hay $d_{i} =  \displaystyle \sum _{j=1}^{n}m_{ij}$. Khi đó:
\begin{equation*}
    per M \leq \prod_{i=1}^{n}(d_{i}!)^{1/d_{i}}.
\end{equation*}

\textit{Chứng minh:} Xét $G=(U \cup V,E)$ là đồ thị hai phía tương ứng với ma trận $M$, trong đó $d_{i}$ là bậc tương ứng của các đỉnh $u_{i}$, và kí hiệu $\Sigma$ là tập các \textit{perfect matching} của G. Vì $per M=m(G) = |\Sigma|$ nên thay vì tìm cận trên cho $per M$ như định lý 1, ta sẽ tìm cận trên cho $|\Sigma|$. Giả sử $|\Sigma| \neq 0$ và mỗi $\sigma \in \Sigma$ là một hoán vị tương ứng $\sigma (1) \sigma (2) ....  \sigma (n)$ của các chỉ số. Vì vậy, tương ứng với mỗi giá trị $u_{i} \in U$ là một giá trị $v_{\sigma(i)} \in U$ theo phép song ánh $\sigma$
\\
Ý tưởng ban đầu là chọn $\sigma$ một cách ngẫu nhiên và xét biến ngẫu nhiên $X=(X_{1},X_{2},..,X_{n}) = (\sigma(1),\sigma(2),...,\sigma(n)).$
\\
Theo mệnh đề \textbf{(A)},
\begin{equation*}
H(\sigma (1), \sigma (2), ....  ,\sigma (n)) = \log_{2}(|\Sigma|)
\end{equation*}

Do đó chỉ cần chỉ ra
\begin{equation}
    H(\sigma(1),...,\sigma(n)) \leq \log_{2}(\prod_{i=1}^{n}(d_{i}!)^{1/d_{i}}) = \sum_{i=1}^{n}\frac{1}{d_{i}}\log_{2}(d_{i}!).
\end{equation}

Sử dụng mệnh đề \textbf{(B)}, ta có
\begin{equation}
H(\sigma (1), \sigma (2), ....  ,\sigma (n)) = \displaystyle \sum_{i=1}^{n}H(\sigma (i)| \sigma (1), \sigma (2), ....  ,\sigma (i-1))
\end{equation}
%$\sigma (\tau (1)), \sigma (\tau (2)), .... , \sigma (\tau (n))$
Ý tưởng của Radhakrishnan là xét các đỉnh  $u_{1}, u_{2}, ....  , u_{n}$ theo một \textit{thứ tự ngẫu nhiên $\tau \in S_{n}$} , với xác suất là như nhau và bằng $\frac{1}{n!}$, và lấy giá trị kì vọng của các entropy. Nói cách khác, ta xét các cặp \textit{matching} theo thứ tự $\tau_{1},\tau_{2},..,\tau_{n}$ . Xét $\tau$ cố định, khi đó $k_{i} = \tau ^{-1}_{i}$ được hiểu là vị trí của $u_{i}$ theo thứ tự ngẫu nhiên $\tau$ là $k_{i}$. Khi đó, biểu thức (2) trở thành:
\begin{equation*}
	H(\sigma(1),...,\sigma(n)) = \displaystyle \sum_{i=1}^{n}H\Big(\sigma (i)| \sigma (\tau_{1}),...,\sigma (\tau_{k_{i}-1})\Big)
\end{equation*}
%H(\sigma(1),...,\sigma(n)) = \displaystyle \sum_{i=1}^{n}H(\sigma (i)| \sigma (\tau(1)),...,\sigma (\tau(k_{i}-1)))	
Khi đó
%\begin{equation*}
%	H(\sigma(1),...,\sigma(n)) = \frac{1}{n!}\displaystyle \sum_{\tau}\Bigg(\displaystyle \sum_{i=1}^{n}H(\sigma (i)| \sigma (\tau(1)),...,\sigma (\tau(k_{i}-1))) \Bigg)
%\end{equation*}
\begin{equation*}
	H(\sigma(1),...,\sigma(n)) = \frac{1}{n!}\displaystyle \sum_{i=1}^{n}H\Big(\sigma (i)| \sigma (\tau_{1}),...,\sigma (\tau_{k_{i}-1})\Big)
\end{equation*}

Xét biểu thức 
%\begin{equation}
%H(\sigma (i)| \sigma (\tau(1)),...,\sigma (\tau(k_{i}-1)))
%\end{equation}
\begin{equation}
H\Big(\sigma (i)| \sigma (\tau_{1}),...,\sigma (\tau_{k_{i}-1})\Big)
\end{equation}
\\

Để tìm cận trên cho , ta sẽ sử dụng mệnh đề \textbf{(C)}, áp dụng với biến ngẫu nhiên $X=\Big( \sigma (\tau_{1}),...,\sigma (\tau_{k_{i}-1}) \Big)$ và $Y=\sigma(i)$. Với $\tau$ cố định $\in S_{n}$ và $\sigma \in \Sigma$ đặt $N_{i}(\sigma,\tau)$ là số các giá trị $k \in [n]$ sao cho $u_{i}v_{k} \in E(G)$ và k $\notin {\Big(\sigma(\tau_{1}),...,\sigma(\tau_{k_{i}-1}) \Big)}$ (nói cách khác, $N_{i}(\sigma,\tau)$ là số khả năng còn lại cho $\sigma(i)$ khi đã biết $\sigma(\tau_{1}),...,\sigma(\tau_{k_{i}-1})$). Vì $deg(u_{i}) = d_{i}$  đồng thời $u_{i}$ phải được ghép cặp trong $\sigma$ nên $1 \leq N_{i}(\sigma,\tau) \leq d_{i} $ với mọi $\sigma \in \Sigma$. Tiến hành chi tập $supp X$ thành các tập con $E_{i,j}^{(\tau)}$ sao cho : 
\begin{equation*}
\Big(\sigma(\tau_{1}),...,\sigma(\tau_{k_{i}-1}) \Big) \in E_{i,j}^{(\tau)} <=> N_{i}(\sigma,\tau) = j, \textrm{ với } 1 \leq j \leq d_{i}
\end{equation*}
Coi $N_{i}(\sigma,\tau)$ là một biến ngẫu nhiên trên $\Sigma$, ta có:
\begin{equation*}
Prob(X \in  E_{i,j}^{(\tau)} ) = Prob( N_{i}(\sigma,\tau) = j)
\end{equation*}
Từ mệnh đề \textbf{(C)}, với $\tau$ cố định:
\begin{equation*}
\begin{array}{l@{}l}
H(\sigma (i)| \sigma (\tau_{1}),...,\sigma (\tau_{k_{i}-1})) 
    &{} \leq \displaystyle \sum_{j=1}^{d_{i}}Prob(|N_{i}(\sigma,\tau)|=j)\log_{2}j \\
    &{} = \displaystyle \sum_{j=1}^{d_{i}}\log_{2}j\displaystyle \sum_{\sigma \in \Sigma}P(\sigma).P(N_{i}(\sigma,\tau)=j | \sigma)  \textrm{ (Do } {\sigma \in \Sigma}  \textrm{ là 1 nhóm đầy đủ)}\\
    &{} = \displaystyle \sum_{j=1}^{d_{i}}\log_{2}j\displaystyle \sum_{\sigma \in \Sigma}\frac{P(N_{i}(\sigma,\tau)=j | \sigma)}{|\Sigma|}
\end{array}
\end{equation*}

Kết hợp với ... 
\begin{equation}
    H(\sigma (1),...,\sigma (n)) \leq \displaystyle \sum_{j=1}^{d_{i}}\log_{2}j \Bigg( \frac{1}{n!|\Sigma|} \displaystyle \sum_{\sigma \in \Sigma}\displaystyle \sum_{\tau \in S_{n}}P(N_{i}(\sigma,\tau)=j | \sigma) \Bigg)
\end{equation}


Xét $\displaystyle \sum_{\tau \in S_{n}}P(N_{i}(\sigma,\tau)=j | \sigma)$ \\
Với mỗi $\sigma$ cố định $\in \Sigma$ và trên từng hoán vị $\tau \in S_{n}$,  $N_{i}(\sigma,\tau)$ nhận các giá trị từ 1 tới $d_{i}$ với xác suất như nhau là $\frac{1}{d_{i}}$, vì $N_{i}(\sigma,\tau)$ chỉ phụ thuộc vào vị trí của $\sigma(i)$ trong hoán vị $\tau$ (do $\sigma$ đã cố định), tương ứng với các đỉnh $k$ thỏa mãn $u_{i}v_{k} \in E(G)$ (Nếu  $\sigma(i)$ là lân cận gần nhất của $i$ theo thứ tự của hoán vị (giả sử là $\tau_{1}$).  Khi đó $N_{i}(\sigma,\tau_{1}) = d_{i}$ và $P(N_{i}(\sigma,\tau_{1})=d_{i} | \sigma)=\frac{1}{d_{i}}$; Nếu  $\sigma(i)$ là lân cận gần thứ hai của $i$ theo thứ tự của hoán vị (giả sử $\tau_{2}$). Khi đó $N_{i}(\sigma,\tau_{2}) = d_{i}-1$ và $P(N_{i}(\sigma,\tau_{2})=d_{i}-1 | \sigma)=\frac{1}{d_{i}}$,...tương tự với n! hoán vị của $S_{n}$ .Do đó, giá trị của biểu thức trên bằng:
\begin{equation*}
    \displaystyle \sum_{\tau \in S_{n}}P(N_{i}(\sigma,\tau)=j | \sigma)=n!.\frac{1}{d_{i}} = \frac{n!}{d_{i}}
\end{equation*}
Và biểu thức (2) trở thành:
\begin{equation*}
\begin{array}{l@{}l}
H(\sigma (1), \sigma (2), ....  ,\sigma (n)) 
&{}= \displaystyle \sum_{i=1}^{n}H(\sigma (i)| \sigma (1), \sigma (2), ....  ,\sigma (i-1)) \\
&{} =  \displaystyle \sum_{i=1}^{n}\displaystyle \sum_{j=1}^{d_{i}}\log_{2}j \Bigg(\frac{1}{n!|\Sigma|}\displaystyle \sum_{\sigma \in \Sigma}\frac{n!}{d_{i}} \Bigg) \\
 &{}= \displaystyle \sum_{i=1}^{n}\displaystyle \sum_{j=1}^{d_{i}}\log_{2}j \Bigg(\frac{1}{n!|\Sigma|}.|\Sigma|.\frac{n!}{d_{i}} \Bigg) \\
 &{}= \displaystyle \sum_{i=1}^{n}\displaystyle \sum_{j=1}^{d_{i}}\log_{2}j.\frac{1}{d_{i}} =\displaystyle \sum_{i=1}^{n} \frac{\log_{2}d_{i}!}{d_{i}}  \;\;\;\;\;\; \textrm{              (đpcm)}
\end{array}
\end{equation*}






%$\sigma (\tau_{1}), \sigma (\tau_{2}), .... , \sigma (\tau_{n})$
%
%$H(\sigma (\tau_{1}),..,\sigma (\tau_{n})) = \displaystyle \sum_{i=1}^{n}H(\sigma (\tau_{i})| \sigma (\tau_{1}),...,\sigma (\tau_{k_{i}-1}))$
%
%$H(\sigma (\tau_{1}),..,\sigma (\tau_{n})) = \frac{1}{n!}\displaystyle \sum _{\tau}\left ( \displaystyle \sum_{i=1}^{n}H(\sigma (\tau_{i})| \sigma (\tau_{1}),...,\sigma (\tau_{k_{i}-1})) \right )$
%
%$\Theta(n^{\log_2 2} )$
\end{document}